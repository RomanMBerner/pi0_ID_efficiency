{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../lartpc_mlreco3d\")\n",
    "sys.path.append(\"../../pi0_reco\")\n",
    "\n",
    "import yaml\n",
    "# Configuration for the data loader\n",
    "io_cfg = \"\"\"\n",
    "iotool:\n",
    "  batch_size: 1\n",
    "  shuffle: False\n",
    "  num_workers: 1\n",
    "  collate_fn: CollateSparse\n",
    "  dataset:\n",
    "    name: LArCVDataset\n",
    "    data_keys:\n",
    "     #- /gpfs/slac/staas/fs1/g/neutrino/kterao/data/mpvmpr_2020_01_v04/train.root\n",
    "     - /home/rberner/cernbox/PhD/pi0_reconstruction/reco_software/data/train.root\n",
    "    limit_num_files: 25\n",
    "    schema:\n",
    "      input_data:\n",
    "        - parse_sparse3d_scn\n",
    "        - sparse3d_pcluster\n",
    "      segment_label:\n",
    "        - parse_sparse3d_scn\n",
    "        - sparse3d_pcluster_semantics\n",
    "      cluster_label:\n",
    "        - parse_cluster3d_full\n",
    "        - cluster3d_pcluster\n",
    "        - particle_corrected\n",
    "      particles:\n",
    "        - parse_particle_asis\n",
    "        - particle_corrected\n",
    "        - cluster3d_pcluster\n",
    "      ppn_label:\n",
    "        - parse_particle_points\n",
    "        - sparse3d_pcluster\n",
    "        - particle_corrected\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration of the reconstruction chain\n",
    "chain_cfg = '''\n",
    "name: pi0_chain_test\n",
    "net_cfg: /home/rberner/cernbox/PhD/pi0_reconstruction/reco_software/config_files/uresnet_ppn.cfg\n",
    "segment:               label  # label, uresnet\n",
    "deghost:                      # label, uresnet\n",
    "charge2energy:         null # null, constant, average(, full, enet)\n",
    "charge2energy_cst:     0.0082 # energy response constant (0.0082 for mask, 0.0052 for uresnet)\n",
    "charge2energy_average: 0.877  # energy response average (1.3693 for mask, 0.877 for uresnet)\n",
    "shower_start:          label  # label, ppn\n",
    "shower_fragment:       label  # label, dbscan\n",
    "shower_direction:      label  # label, pca, cent\n",
    "shower_cluster:        label  # label, cone\n",
    "shower_cluster_params:\n",
    "  IP: 40\n",
    "  Distance: 300\n",
    "shower_energy:         pixel_sum  # label, pixel_sum\n",
    "shower_match:          label  # label, proximity\n",
    "refit_dir:             true   # true, false\n",
    "refit_cone:            true   # true, false\n",
    "'''\n",
    "chain_cfg = yaml.load(chain_cfg,Loader=yaml.Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "# Decorative progress bar\n",
    "def progress(count, total, unit, message=''):\n",
    "    return HTML(\"\"\"\n",
    "        <progress \n",
    "            value='{count}'\n",
    "            max='{total}',\n",
    "            style='width: 30%'\n",
    "        >\n",
    "            {count}\n",
    "        </progress> {count}/{total} {unit} ({frac}%) ... {message}\n",
    "    \"\"\".format(count=count, total=total, unit=unit, frac=int(float(count)/float(total)*100.),message=message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.16/00\n",
      "Initialized Pi0 mass chain, log path: pi0_chain_test_log.csv\n",
      "\n",
      "Config processed at: Linux rberner-X1 5.3.0-28-generic #30~18.04.1-Ubuntu SMP Fri Jan 17 06:14:09 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux\n",
      "\n",
      "$CUDA_VISIBLE_DEVICES=\"None\"\n",
      "\n",
      "{   'iotool': {   'batch_size': 1,\n",
      "                  'collate_fn': 'CollateSparse',\n",
      "                  'dataset': {   'data_keys': [   '/home/rberner/cernbox/PhD/pi0_reconstruction/reco_software/data/train.root'],\n",
      "                                 'limit_num_files': 25,\n",
      "                                 'name': 'LArCVDataset',\n",
      "                                 'schema': {   'cluster_label': [   'parse_cluster3d_full',\n",
      "                                                                    'cluster3d_pcluster',\n",
      "                                                                    'particle_corrected'],\n",
      "                                               'input_data': [   'parse_sparse3d_scn',\n",
      "                                                                 'sparse3d_pcluster'],\n",
      "                                               'particles': [   'parse_particle_asis',\n",
      "                                                                'particle_corrected',\n",
      "                                                                'cluster3d_pcluster'],\n",
      "                                               'ppn_label': [   'parse_particle_points',\n",
      "                                                                'sparse3d_pcluster',\n",
      "                                                                'particle_corrected'],\n",
      "                                               'segment_label': [   'parse_sparse3d_scn',\n",
      "                                                                    'sparse3d_pcluster_semantics']}},\n",
      "                  'minibatch_size': 1,\n",
      "                  'num_workers': 1,\n",
      "                  'shuffle': False}}\n",
      "Loading file: /home/rberner/cernbox/PhD/pi0_reconstruction/reco_software/data/train.root\n",
      "Loading tree sparse3d_pcluster\n",
      "Loading tree sparse3d_pcluster_semantics\n",
      "Loading tree cluster3d_pcluster\n",
      "Loading tree particle_corrected\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <progress \n",
       "            value='5'\n",
       "            max='5',\n",
       "            style='width: 30%'\n",
       "        >\n",
       "            5\n",
       "        </progress> 5/5 images (100%) ... \n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " event:  0\n",
      " event:  1\n",
      " event:  2\n",
      " event:  3\n",
      " event:  4\n"
     ]
    }
   ],
   "source": [
    "# Initialize the chain\n",
    "from pi0.chain import Pi0Chain\n",
    "chain = Pi0Chain(io_cfg, chain_cfg)\n",
    "from larcv import larcv\n",
    "import numpy as np\n",
    "from numpy import linalg\n",
    "\n",
    "# Loop over the full dataset\n",
    "masses = []\n",
    "i_draw, n_draw = 0, 1\n",
    "data_size = 5 #len(chain.hs.data_io) # len(chain.hs.data_io) = 125480\n",
    "out = display(progress(0,data_size,'images'),display_id=True)\n",
    "\n",
    "# Create CSV file for all true pi0s in the event\n",
    "from mlreco.utils import CSVData\n",
    "log_path_true_pi0 = 'true_pi0s.csv'\n",
    "log_true_pi0 = CSVData(log_path_true_pi0)\n",
    "\n",
    "# Create CSV file for all groups (group = collection of clusters) in the event\n",
    "#from mlreco.utils import CSVData\n",
    "#log_path_showers = 'showers.csv'\n",
    "#log_showers = CSVData(log_path_showers)\n",
    "\n",
    "for ev in range(data_size):\n",
    "    #if ev != 85:\n",
    "    #    continue\n",
    "    #if ev < 80:\n",
    "    #    continue\n",
    "    print(' event: ', ev)\n",
    "\n",
    "    # Loop over events and log informations in .csv file\n",
    "    # ------------------------------------------------------\n",
    "    chain.run_loop()\n",
    "\n",
    "    #print(' ====================== ============== ======================')\n",
    "    #print(' ======================   TRUE  INFO   ======================')\n",
    "    #print(' ====================== ============== ======================')\n",
    "    # Loop over all particles in the event and obtain true pi0->gamma+gamma info:\n",
    "    # Note: primary pi0 are not stored in chain.event['particles']\n",
    "    n_pi0_in_event           = 0   # [-]\n",
    "    n_true_gammas            = 0   # [-]\n",
    "    n_reco_gammas            = 0   # [-]\n",
    "    pi0_track_ids            = []  # [-]\n",
    "    pi0_pdg_code             = []  # [-]\n",
    "    true_gammas_group_ids    = []  # [-]\n",
    "    gamma_1_track_id         = []  # [-]\n",
    "    gamma_1_pdg_code         = []  # [-]\n",
    "    gamma_1_mom              = []  # [MeV/c]\n",
    "    gamma_1_first_step       = []  # [x, y, z]\n",
    "    gamma_1_pos              = []  # [x, y, z]\n",
    "    gamma_1_ekin             = []  # [MeV]\n",
    "    gamma_1_energy_deposit   = []  # [MeV]\n",
    "    gamma_1_num_voxels       = []  # [-]\n",
    "    gamma_2_track_id         = []  # [-]\n",
    "    gamma_2_pdg_code         = []  # [-]\n",
    "    gamma_2_mom              = []  # [MeV/c]\n",
    "    gamma_2_first_step       = []  # [x, y, z]\n",
    "    gamma_2_pos              = []  # [x, y, z]\n",
    "    gamma_2_ekin             = []  # [MeV]\n",
    "    gamma_2_energy_deposit   = []  # [MeV]\n",
    "    gamma_2_num_voxels       = []  # [-]\n",
    "\n",
    "\n",
    "    for particle in range(len(chain.event['particles'][0])):\n",
    "        p = chain.event['particles'][0][particle]\n",
    "        if p.parent_pdg_code() == 111 and p.pdg_code() == 22:\n",
    "            n_true_gammas += 1\n",
    "            if p.group_id() not in true_gammas_group_ids:\n",
    "                true_gammas_group_ids.append(p.group_id())\n",
    "\n",
    "            #print('\\n----------------------------------------------- GENERAL ------------------------------------------------')\n",
    "            #print(' Event Nr.: \\t \\t \\t ', ev, '\\n')\n",
    "            #print(p.dump())\n",
    "            \n",
    "            '''\n",
    "            print('\\n----------------------------------------------- ANCESTOR -----------------------------------------------')\n",
    "            print(' ancestor_track_id: \\t \\t ',      p.ancestor_track_id())\n",
    "            print(' ancestor_pdg_code: \\t \\t ',      p.ancestor_pdg_code())\n",
    "            print(' ancestor_creation_process: \\t ', p.ancestor_creation_process())\n",
    "            print(' ancestor_position: \\t \\t ',      p.ancestor_position().x(), p.ancestor_position().y(), p.ancestor_position().z())\n",
    "            print(' ancestor_t: \\t \\t \\t ',          p.ancestor_t())\n",
    "            print(' ancestor x,y,z: \\t \\t ',         p.ancestor_x(), p.ancestor_y(), p.ancestor_z())\n",
    "            print('\\n------------------------------------------------ PARENT ------------------------------------------------')\n",
    "            print(' parent_track_id: \\t \\t ',        p.parent_track_id())\n",
    "            print(' parent_id: \\t \\t \\t ',           p.parent_id())\n",
    "            print(' parent_pdg_code: \\t \\t ',        p.parent_pdg_code())\n",
    "            print(' parent_creation_process: \\t ',   p.parent_creation_process())\n",
    "            ##print(' parent_position: \\t \\t  (',      p.parent_position().x(), ' , ', p.parent_position().y(), ' , ', p.parent_position().z(), ')')   # This probably is not meaningful for primary pi0 (is it filled properly?)\n",
    "            ##print(' parent_t: \\t \\t \\t ',            p.parent_t())   # This probably is not meaningful for primary pi0 (is it filled properly?)\n",
    "            ##print(' parent_x: \\t \\t \\t ',            p.parent_x())   # This probably is not meaningful for primary pi0 (is it filled properly?)\n",
    "            ##print(' parent_y: \\t \\t \\t ',            p.parent_y())   # This probably is not meaningful for primary pi0 (is it filled properly?)\n",
    "            ##print(' parent_z: \\t \\t \\t ',            p.parent_z())   # This probably is not meaningful for primary pi0 (is it filled properly?)\n",
    "            '''\n",
    "            '''\n",
    "            print('\\n------------------------------------------------ PHOTON ------------------------------------------------')\n",
    "            #print(' boundingbox_2d: ', p.boundingbox_2d())\n",
    "            #print(' boundingbox_3d: ', p.boundingbox_3d())\n",
    "            print(' track_id: \\t \\t \\t ',            p.track_id())\n",
    "            print(' id: \\t \\t \\t \\t ',               p.id())\n",
    "            print(' pdg_code: \\t \\t \\t ',            p.pdg_code())\n",
    "            #print(' creation_process : \\t \\t ',      p.creation_process())\n",
    "            #print(' nu_interaction_type: \\t \\t ',    p.nu_interaction_type())\n",
    "            #print(' interaction_id: \\t \\t ',         p.interaction_id())\n",
    "            #print(' nu_current_type: \\t \\t ',        p.nu_current_type())\n",
    "            \n",
    "            \n",
    "            print(' group_id: \\t \\t \\t ',            p.group_id())\n",
    "            print(' children_id: \\t \\t \\t ',         p.children_id())\n",
    "            #print(' shape: \\t \\t \\t ',               p.shape())\n",
    "            print(' energy_init: \\t \\t \\t ',         p.energy_init())\n",
    "            print(' energy_deposit: \\t \\t ',         p.energy_deposit())\n",
    "            print(' num_voxels: \\t \\t \\t ',          p.num_voxels())\n",
    "\n",
    "            print(' first_step: \\t \\t \\t  (',        p.first_step().x(), ' , ', p.first_step().y(), ' , ', p.first_step().z(), ')')\n",
    "            print(' last_step: \\t \\t \\t  (',         p.last_step().x(), ' , ', p.last_step().y(), ' , ', p.last_step().z(), ')')\n",
    "            #print(' end_position: \\t \\t \\t  (',      p.end_position().x(), ' , ', p.end_position().y(), ' , ', p.end_position().z(), ')')\n",
    "            #print(' distance_travel: \\t \\t ',        p.distance_travel())\n",
    "            '''\n",
    "            '''\n",
    "            print(' momentum: ', p.momentum().x())\n",
    "            print(' p: \\t \\t \\t \\t ',                p.p())\n",
    "            print(' px: \\t \\t \\t \\t ',               p.px())\n",
    "            print(' py: \\t \\t \\t \\t ',               p.py())\n",
    "            print(' pz: \\t \\t \\t \\t ',               p.pz())\n",
    "            print(' ------------------------------------------- ')\n",
    "\n",
    "            print(' vertex position: \\t \\t  (',      p.position().x(), ' , ', p.position().y(), ' , ', p.position().z(), ')')\n",
    "            print(' vertex t: \\t \\t \\t ',            p.t())\n",
    "            print(' vertex x: \\t \\t \\t ',            p.x())  # corresponds to the pi0 -> gamma+gamma vertex\n",
    "            print(' vertex y: \\t \\t \\t ',            p.y())  # corresponds to the pi0 -> gamma+gamma vertex\n",
    "            print(' vertex z: \\t \\t \\t ',            p.z())  # corresponds to the pi0 -> gamma+gamma vertex\n",
    "            #print('--------------------------------------------------------------------------------------------------------')\n",
    "            '''\n",
    "\n",
    "            if p.parent_track_id() not in pi0_track_ids:\n",
    "                n_pi0_in_event += 1\n",
    "                pi0_track_ids.append(p.parent_track_id())\n",
    "                pi0_pdg_code.append(p.parent_pdg_code())\n",
    "                gamma_1_track_id.append(p.track_id())\n",
    "                gamma_1_pdg_code.append(p.pdg_code())\n",
    "                gamma_1_mom.append([p.px(),p.py(),p.pz()])\n",
    "                gamma_1_first_step.append([p.first_step().x(),p.first_step().y(),p.first_step().z()])\n",
    "                gamma_1_pos.append([p.x(),p.y(),p.z()])  # corresponds to the pi0 -> gamma+gamma vertex\n",
    "                gamma_1_ekin.append(p.energy_init())     # initial energy of photon, = np.sqrt(p.px()**2+p.py()**2+p.pz()**2)\n",
    "                gamma_1_energy_deposit.append(p.energy_deposit())\n",
    "                gamma_1_num_voxels.append(p.num_voxels())\n",
    "            else:\n",
    "                # check whether ther pi0 track id corresponds to the latest one (in order to not assign the photon to a wrong parent)\n",
    "                if p.parent_track_id() == pi0_track_ids[len(pi0_track_ids)-1]:\n",
    "                    #pi0_track_ids.append(p.parent_track_id())\n",
    "                    pi0_pdg_code.append(p.parent_pdg_code())\n",
    "                    gamma_2_track_id.append(p.track_id())\n",
    "                    gamma_2_pdg_code.append(p.pdg_code())\n",
    "                    gamma_2_mom.append([p.px(),p.py(),p.pz()])\n",
    "                    gamma_2_first_step.append([p.first_step().x(),p.first_step().y(),p.first_step().z()])\n",
    "                    gamma_2_pos.append([p.x(),p.y(),p.z()])  # corresponds to the pi0 -> gamma+gamma vertex\n",
    "                    gamma_2_ekin.append(p.energy_init())     # initial energy of photon, = np.sqrt(p.px()**2+p.py()**2+p.pz()**2)\n",
    "                    gamma_2_energy_deposit.append(p.energy_deposit())\n",
    "                    gamma_2_num_voxels.append(p.num_voxels())\n",
    "                else:\n",
    "                    print('WARNING: Assigning a gamma to the wrong parent ...')\n",
    "    \n",
    "    #print(' true_gammas_group_ids: ', true_gammas_group_ids)\n",
    "\n",
    "\n",
    "    # Loop over all particles and build lists with track IDs produced by photons originated by neutral pion decays\n",
    "    # ------------------------------------------------------\n",
    "    if n_true_gammas > 0:\n",
    "        particle_ids_gamma_showers = [[] for _ in range(n_true_gammas)] # particle IDs of all particles corresponding to a true shower (produced by photon from pi0 decay)\n",
    "        track_ids_showers          = [[] for _ in range(n_true_gammas)] #    track IDs of all particles corresponding to a true shower (produced by photon from pi0 decay)\n",
    "        true_pixel_sum             = [0. for _ in range(n_true_gammas)] # [MeV]\n",
    "        true_showers_n_voxels      = [[] for _ in range(len(true_gammas_group_ids))] # list of arrays (number of arrays = number of true gammas from pi0 decays). Each array stores as entries: p.num_voxels() for every particle in the shower.\n",
    "        used_particles             = [[] for _ in range(len(true_gammas_group_ids))] # to store the track_ids of all used particles to calc. the showers n_voxels\n",
    "        counter = 0\n",
    "        for particle in range(len(chain.event['particles'][0])):\n",
    "            p = chain.event['particles'][0][particle]\n",
    "            if p.parent_pdg_code() == 111 and p.pdg_code() == 22:\n",
    "                particle_ids_gamma_showers[counter].append(p.id())\n",
    "                track_ids_showers[counter].append(p.track_id())\n",
    "                true_pixel_sum[counter] += p.energy_deposit() # Note: photons can have edep > 0: e+/e- pair production is recorded as a photon\n",
    "                counter += 1\n",
    "            if p.group_id() in true_gammas_group_ids:\n",
    "                for index in range(len(true_gammas_group_ids)):\n",
    "                    if true_gammas_group_ids[index] == p.group_id():\n",
    "                        if index not in used_particles[index]:\n",
    "                            true_showers_n_voxels[index].append(p.num_voxels())\n",
    "                            #print(' voxels: ', p.num_voxels())\n",
    "                            used_particles[index].append(p.track_id())\n",
    "        '''\n",
    "        print(' used_particles: ', used_particles)\n",
    "        print(' true_showers_n_voxels: ', true_showers_n_voxels)\n",
    "        '''\n",
    "        \n",
    "\n",
    "        '''\n",
    "        print(' particle_ids_gamma_showers: ', particle_ids_gamma_showers)\n",
    "        print(' track_ids_showers: ', track_ids_showers)\n",
    "        print(' ---------------------------------------------------------------------- ')\n",
    "        '''\n",
    "\n",
    "        for particle in range(len(chain.event['particles'][0])):\n",
    "            p = chain.event['particles'][0][particle]\n",
    "            for gamma in range(n_true_gammas):\n",
    "                if p.parent_id() in particle_ids_gamma_showers[gamma] and p.id() not in particle_ids_gamma_showers[gamma]:\n",
    "                    particle_ids_gamma_showers[gamma].append(p.id())\n",
    "                    true_pixel_sum[gamma] += p.energy_deposit()\n",
    "                    track_ids_showers[gamma].append(p.track_id())\n",
    "                    '''\n",
    "                    print(' \\n ---------------------- PHOTON Nr.', gamma, '---------------------- ')\n",
    "                    print(' parent id: \\t \\t ',    p.parent_id())\n",
    "                    print(' parent track id: \\t ', p.parent_track_id())\n",
    "                    print(' parent pdg: \\t \\t ',   p.parent_pdg_code())\n",
    "                    print(' id: \\t \\t \\t ',        p.id())\n",
    "                    print(' track id: \\t \\t ',     p.track_id())\n",
    "                    print(' pdg: \\t \\t \\t ',       p.pdg_code())\n",
    "                    print(' edep: \\t \\t \\t ',      p.energy_deposit())\n",
    "                    print(' \\n particle_ids_gamma_showers[', gamma, ']: \\n', particle_ids_gamma_showers[gamma])\n",
    "                    print(' \\n track_ids_showers[', gamma, ']: \\n', track_ids_showers[gamma])\n",
    "                    print(' \\n pixel sums: \\n', true_pixel_sum)\n",
    "                    '''\n",
    "        '''\n",
    "        print(' particle_ids_gamma_showers: ', particle_ids_gamma_showers)\n",
    "        print(' track_ids_showers: ', track_ids_showers)\n",
    "        print(' pixel sum: ', true_pixel_sum)\n",
    "        '''\n",
    "\n",
    "\n",
    "\n",
    "    #print(' ====================== ============== ======================')\n",
    "    #print(' ====================== RECONSTRUCTION ======================')\n",
    "    #print(' ====================== ============== ======================')\n",
    "    # For all reconstructed showers (can much more than true showers)\n",
    "    reco_showers_start_pos = []\n",
    "    reco_showers_dir       = []\n",
    "    reco_showers_voxels    = []\n",
    "    reco_showers_energy    = []\n",
    "    reco_showers_pid       = []\n",
    "\n",
    "    # For each true shower only, assign the reconstructed shower which has reco start point closest to the true shower\n",
    "    # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    # POSSIBLE POINT OF FAILURE: IF n_reco_showers < n_true_showers\n",
    "    # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    closest_reco_showers_first_step = np.zeros((n_true_gammas, 3))\n",
    "    closest_reco_showers_dir        = np.zeros((n_true_gammas, 3))\n",
    "    closest_reco_showers_n_voxels   = np.zeros((n_true_gammas, 1))\n",
    "    closest_reco_showers_energy     = np.zeros((n_true_gammas, 1))\n",
    "\n",
    "    \n",
    "    # Loop over all (reconstructed) showers:\n",
    "    # ------------------------------------------------------\n",
    "    showers = chain.output['showers']\n",
    "    n_reco_gammas = len(showers)\n",
    "    for sh in range(len(showers)):\n",
    "        reco_showers_start_pos.append(np.array(showers[sh].start))\n",
    "        reco_showers_dir.      append(np.array(showers[sh].direction))\n",
    "        reco_showers_voxels.   append(np.array(showers[sh].voxels))\n",
    "        reco_showers_energy.   append(showers[sh].energy)\n",
    "        reco_showers_pid.      append(showers[sh].pid)\n",
    "        '''\n",
    "        #print('start: \\t ',    np.array(showers[sh].start))\n",
    "        #print('dir: \\t ',      np.array(showers[sh].direction))\n",
    "        #print('voxels: ',      showers[sh].voxels)\n",
    "        #print('voxels: ',      showers[sh].voxels[0:10])\n",
    "        #print('n voxels: ',    len(showers[sh].voxels))\n",
    "        #print('energy: \\t ',   showers[sh].energy)\n",
    "        #print('pid: \\t ',      showers[sh].pid)\n",
    "        #print(' ------------------------------------------- ')\n",
    "        '''\n",
    "\n",
    "\n",
    "    # Get true gamma's directions in order to associate the reconstructed showers to the true\n",
    "    # ------------------------------------------------------\n",
    "    true_photons_first_steps = []\n",
    "    true_photons_energies = []\n",
    "    for particle in range(len(chain.event['particles'][0])):\n",
    "        p = chain.event['particles'][0][particle]\n",
    "        if p.parent_pdg_code() == 111 and p.pdg_code() == 22:\n",
    "            true_photons_first_steps.append(np.array([p.first_step().x(),p.first_step().y(),p.first_step().z()]))\n",
    "            true_photons_energies.append(np.sqrt(p.px()**2+p.py()**2+p.pz()**2))\n",
    "    '''\n",
    "    #print(' true_photons_first_steps: \\n ', true_photons_first_steps)\n",
    "    #print(' true_photons_energies [MeV]: ', true_photons_energies)\n",
    "    '''\n",
    "\n",
    "\n",
    "    # Get the distances between the reconstructed shower's starting points\n",
    "    # (note: each group is considered as a single shower)\n",
    "    # and the true gamma's start points (first_step).\n",
    "    # Calculate the pairwise distances between reco start and true start positions -> yields matrix.\n",
    "    # Assign true shower to reco shower by taking the first minimum from the matrix,\n",
    "    # then the second minimum, and so on.\n",
    "    # First, create the matrix with the pairwise distances, which\n",
    "    # is a matrix of dimensions N_true_showers x N_reco_showers)\n",
    "    # Then, sum the energy deposits in each group and compare it with the true photon's energy.\n",
    "    # Note: could do it also with the true group's start point\n",
    "    # -> look for the gamma which produced this group (closest true gamma end point).\n",
    "    # ------------------------------------------------------\n",
    "    distances = np.zeros((len(true_photons_first_steps), len(reco_showers_start_pos)))\n",
    "    for true_sh in range(len(true_photons_first_steps)):\n",
    "        minimum_temp = 999.9\n",
    "        for reco_sh in range(len(reco_showers_start_pos)):\n",
    "            distances[true_sh][reco_sh] = linalg.norm(true_photons_first_steps[true_sh]-reco_showers_start_pos[reco_sh])\n",
    "            '''\n",
    "            #print(' distances: ', distances[true][reco])\n",
    "            #print(' minimum_temp: ', minimum_temp)\n",
    "            '''\n",
    "\n",
    "    # Get the minima of the distances matrix\n",
    "    # ------------------------------------------------------\n",
    "    for true_gamma in range(n_true_gammas):\n",
    "        if n_reco_gammas > 0:\n",
    "            a, b = np.where(distances == np.min(distances)) # from the whole 2D array, pick the smallest value\n",
    "            #print(' a: ', a[0])\n",
    "            #print(' b: ', b[0])\n",
    "            distances[a[0],:] = 9999.9 # set the row of the picked value to a large number in order not to be selected a second time\n",
    "            distances[:,b[0]] = 9999.9 # also for the columns\n",
    "\n",
    "            # assign the closest shower the correct reconstructed shower's variables\n",
    "            try:\n",
    "                closest_reco_showers_first_step[a[0],:] = reco_showers_start_pos[b[0]]\n",
    "                closest_reco_showers_dir[a[0],:]        = reco_showers_dir[b[0]]\n",
    "                closest_reco_showers_n_voxels[a[0],:]   = len(reco_showers_voxels[b[0]])\n",
    "                closest_reco_showers_energy[a[0],:]     = reco_showers_energy[b[0]]\n",
    "            except:\n",
    "                print(' WARNING: Cannot assign reco shower to a true shower. Pass ... ')\n",
    "                print(' Fix this problem some point!! ')\n",
    "                pass\n",
    "    '''\n",
    "    #print(' closest_reco_showers_fist_step: ',   closest_reco_showers_fist_step)\n",
    "    #print(' closest_reco_showers_dir: ',         closest_reco_showers_dir)\n",
    "    #print(' closest_reco_showers_n_voxels[0]: ', closest_reco_showers_n_voxels[0])\n",
    "    #print(' closest_reco_showers_n_voxels[1]: ', closest_reco_showers_n_voxels[1])\n",
    "    '''\n",
    "\n",
    "    # Calculate overlap between true and reco voxels for each shower\n",
    "    # ------------------------------------------------------\n",
    "    if n_true_gammas > 0:\n",
    "        for index in range(len(true_showers_n_voxels)):\n",
    "            '''\n",
    "            #print(' true_showers_n_voxels[', index, '] ', true_showers_n_voxels[index]) # array with n_voxels of each particle in the true shower\n",
    "            print(' true showers voxel count[', index, ']: ', np.sum(true_showers_n_voxels[index]))\n",
    "            print(' reco showers voxel count[', index, ']: ', np.sum(closest_reco_showers_n_voxels[index]))\n",
    "            '''\n",
    "    \n",
    "    \n",
    "\n",
    "    #print(' ====================== ============== ======================')\n",
    "    #print(' ======================  WRITE 2 FILE  ======================')\n",
    "    #print(' ====================== ============== ======================')\n",
    "    # Write data to CSV file\n",
    "    for pi0 in range(len(pi0_track_ids)):\n",
    "        #print(' len(pi0_track_ids): ', len(pi0_track_ids))\n",
    "        #print(' pi0: ', pi0)\n",
    "        try:\n",
    "            log_true_pi0.record(['event','n_pi0_in_event','n_true_gammas_in_event','n_reco_gammas_in_event',\n",
    "                                 'true_pi0_track_id','true_pi0_pdg_code',\n",
    "                                 'true_gamma_1_track_id','true_gamma_1_pdg_code',\n",
    "                                 'true_gamma_1_pos_x','true_gamma_1_pos_y','true_gamma_1_pos_z',  # vertex pi0 -> gamma + gamma\n",
    "                                 'true_gamma_1_mom_x','true_gamma_1_mom_y','true_gamma_1_mom_z',\n",
    "                                 'true_gamma_1_ekin','true_gamma_1_energy_deposit',\n",
    "                                 'true_gamma_1_pixel_sum','true_gamma_1_num_voxels',\n",
    "                                 'true_gamma_1_first_step_x','true_gamma_1_first_step_y','true_gamma_1_first_step_z',\n",
    "                                 'true_gamma_2_track_id','true_gamma_2_pdg_code',\n",
    "                                 'true_gamma_2_pos_x','true_gamma_2_pos_y','true_gamma_2_pos_z',\n",
    "                                 'true_gamma_2_mom_x','true_gamma_2_mom_y','true_gamma_2_mom_z',\n",
    "                                 'true_gamma_2_ekin','true_gamma_2_energy_deposit',\n",
    "                                 'true_gamma_2_pixel_sum','true_gamma_2_num_voxels',\n",
    "                                 'true_gamma_2_first_step_x','true_gamma_2_first_step_y','true_gamma_2_first_step_z',\n",
    "\n",
    "                                 'reco_gamma_1_first_step_x','reco_gamma_1_first_step_y','reco_gamma_1_first_step_z',\n",
    "                                 'reco_gamma_1_dir_x','reco_gamma_1_dir_y','reco_gamma_1_dir_z',\n",
    "                                 'reco_gamma_1_energy','reco_gamma_1_num_voxels',\n",
    "                                 'reco_gamma_2_first_step_x','reco_gamma_2_first_step_y','reco_gamma_2_first_step_z',\n",
    "                                 'reco_gamma_2_dir_x','reco_gamma_2_dir_y','reco_gamma_2_dir_z',\n",
    "                                 'reco_gamma_2_energy','reco_gamma_2_num_voxels',\n",
    "                                 'reco_pi0_mass'\n",
    "                                ],\n",
    "                                [ev,n_pi0_in_event,n_true_gammas,n_reco_gammas,\n",
    "                                 pi0_track_ids[pi0],pi0_pdg_code[pi0],\n",
    "                                 gamma_1_track_id[pi0],gamma_1_pdg_code[pi0],\n",
    "                                 gamma_1_pos[pi0][0],gamma_1_pos[pi0][1],gamma_1_pos[pi0][2],  # vertex pi0 -> gamma + gamma\n",
    "                                 gamma_1_mom[pi0][0],gamma_1_mom[pi0][1],gamma_1_mom[pi0][2],\n",
    "                                 gamma_1_ekin[pi0],gamma_1_energy_deposit[pi0],\n",
    "                                 true_pixel_sum[pi0],gamma_1_num_voxels[pi0],\n",
    "                                 gamma_1_first_step[pi0][0],gamma_1_first_step[pi0][1],gamma_1_first_step[pi0][2],\n",
    "                                 gamma_2_track_id[pi0],gamma_2_pdg_code[pi0],\n",
    "                                 gamma_2_pos[pi0][0],gamma_2_pos[pi0][1],gamma_2_pos[pi0][2],\n",
    "                                 gamma_2_mom[pi0][0],gamma_2_mom[pi0][1],gamma_2_mom[pi0][2],\n",
    "                                 gamma_2_ekin[pi0],gamma_2_energy_deposit[pi0],\n",
    "                                 true_pixel_sum[pi0+1],gamma_1_num_voxels[pi0],\n",
    "                                 gamma_2_first_step[pi0][0],gamma_2_first_step[pi0][1],gamma_2_first_step[pi0][2],\n",
    "\n",
    "                                 closest_reco_showers_first_step[pi0][0],closest_reco_showers_first_step[pi0][1],closest_reco_showers_first_step[pi0][2],\n",
    "                                 closest_reco_showers_dir[pi0][0],closest_reco_showers_dir[pi0][1],closest_reco_showers_dir[pi0][2],\n",
    "                                 closest_reco_showers_energy[pi0][0],closest_reco_showers_n_voxels[pi0][0],\n",
    "                                 closest_reco_showers_first_step[pi0+1][0],closest_reco_showers_first_step[pi0+1][1],closest_reco_showers_first_step[pi0+1][2],\n",
    "                                 closest_reco_showers_dir[pi0+1][0],closest_reco_showers_dir[pi0+1][1],closest_reco_showers_dir[pi0+1][2],\n",
    "                                 closest_reco_showers_energy[pi0+1][0],closest_reco_showers_n_voxels[pi0+1][0],\n",
    "                                 np.sqrt(2.*closest_reco_showers_energy[pi0][0]*closest_reco_showers_energy[pi0+1][0]*(1.-np.dot(closest_reco_showers_dir[pi0],closest_reco_showers_dir[pi0+1])))\n",
    "                                ])\n",
    "        except IndexError:\n",
    "            print(' IndexError: Fix this problem at some point!! ')\n",
    "        except ValueError:\n",
    "            print(' ValueError: Fix this problem at some point!! ')\n",
    "            pass\n",
    "            # Note: Two gammas, originated from the same pi0 decay, have parent_ids which differ by 1 (e.g. 22 and 23).\n",
    "            # In order to check whether the parent of the two gammas is the same, check for parent_track_id,\n",
    "            # which should be the same for two gammas produced in the same pi0 decay.\n",
    "        log_true_pi0.write()\n",
    "        log_true_pi0.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Draw the last event if requested\n",
    "    # Note: matches: if there are two reco showers pointing to the same point AND\n",
    "    # this point is close to a track\n",
    "\n",
    "    #if 'matches' in chain.output and len(chain.output['matches']) and i_draw < n_draw:\n",
    "    #    chain.draw()\n",
    "    #    i_draw += 1\n",
    "\n",
    "    out.update(progress(ev,data_size,'images'))\n",
    "\n",
    "out.update(progress(data_size,data_size,'images'))\n",
    "\n",
    "# Simplest way to run the full chain\n",
    "#chain = Pi0Chain(io_cfg, chain_cfg)\n",
    "#chain.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport numpy as np\\nimport pandas as pd\\nimport seaborn\\nfrom matplotlib import pyplot as plt\\n\\nseaborn.set(rc={\\'figure.figsize\\':(15, 10),})\\nseaborn.set_context(\\'talk\\') # or paper\\n\\ndef gaus(x, a, mu, sigma):\\n    return  a*np.exp(-(x-mu)**2/2./sigma**2)/np.sqrt(2./np.pi)/sigma\\n\\ndef fit_func(bins, n, func):\\n    from scipy.optimize import curve_fit\\n    center = (bins[:-1] + bins[1:]) / 2\\n    popt, pcov = curve_fit(func, center, n, p0=(100, 100, 10))\\n    print(\" Fitted parameters: \\n a [-]: \\t \", popt[0],\\n          \" \\n μ [MeV/c2]: \\t \", popt[1],\\n          \" \\n σ [MeV/c2]: \\t \", popt[2])\\n\\n    x = np.arange(0, 300, 1)\\n    y = func(x, popt[0], popt[1], popt[2])\\n    plt.plot(x, y, label=\\'Fit: mass=%5.3f, width=%5.3f\\' % (popt[1], popt[2]))\\n    plt.legend()\\n\\n# Load the output file, draw mass peak\\n#df = pd.read_csv(chain_cfg[\\'name\\']+\\'_log.csv\\')\\ndf = pd.read_csv(\\'true_pi0s.csv\\')\\nplt.figure()\\nfig, ax = plt.subplots()\\nn, bins, patches = ax.hist(df.E_kin, bins=60, range=[0,300], alpha=0.75)\\n#np.sqrt(df.px_MeV**2+df.py_MeV**2+df.pz_MeV**2)\\nax.set_xlabel(\\'$\\\\pi^0$ $E_{kin}$ [MeV]\\')\\n#ax.set_xlabel(\\'Invariant $\\\\pi^0$ mass [MeV/c$^2$]\\')\\n\\n# Fit the peak with a Gaussian\\nfit_func(bins, n, gaus)\\nplt.show()\\n\\n# Print pion mass dataframe\\ndf[35:45]\\n#print(df.to_string())\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "seaborn.set(rc={'figure.figsize':(15, 10),})\n",
    "seaborn.set_context('talk') # or paper\n",
    "\n",
    "def gaus(x, a, mu, sigma):\n",
    "    return  a*np.exp(-(x-mu)**2/2./sigma**2)/np.sqrt(2./np.pi)/sigma\n",
    "\n",
    "def fit_func(bins, n, func):\n",
    "    from scipy.optimize import curve_fit\n",
    "    center = (bins[:-1] + bins[1:]) / 2\n",
    "    popt, pcov = curve_fit(func, center, n, p0=(100, 100, 10))\n",
    "    print(\" Fitted parameters: \\n a [-]: \\t \", popt[0],\n",
    "          \" \\n \\u03BC [MeV/c2]: \\t \", popt[1],\n",
    "          \" \\n \\u03C3 [MeV/c2]: \\t \", popt[2])\n",
    "\n",
    "    x = np.arange(0, 300, 1)\n",
    "    y = func(x, popt[0], popt[1], popt[2])\n",
    "    plt.plot(x, y, label='Fit: mass=%5.3f, width=%5.3f' % (popt[1], popt[2]))\n",
    "    plt.legend()\n",
    "\n",
    "# Load the output file, draw mass peak\n",
    "#df = pd.read_csv(chain_cfg['name']+'_log.csv')\n",
    "df = pd.read_csv('true_pi0s.csv')\n",
    "plt.figure()\n",
    "fig, ax = plt.subplots()\n",
    "n, bins, patches = ax.hist(df.E_kin, bins=60, range=[0,300], alpha=0.75)\n",
    "#np.sqrt(df.px_MeV**2+df.py_MeV**2+df.pz_MeV**2)\n",
    "ax.set_xlabel('$\\pi^0$ $E_{kin}$ [MeV]')\n",
    "#ax.set_xlabel('Invariant $\\pi^0$ mass [MeV/c$^2$]')\n",
    "\n",
    "# Fit the peak with a Gaussian\n",
    "fit_func(bins, n, gaus)\n",
    "plt.show()\n",
    "\n",
    "# Print pion mass dataframe\n",
    "df[35:45]\n",
    "#print(df.to_string())\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_data', 'segment_label', 'cluster_label', 'particles', 'ppn_label', 'index'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.event.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cluster_label', 'charge', 'segment', 'shower_mask', 'energy', 'showers'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.output.keys()\n",
    "# Note: The chain produces an output object (chain.output),\n",
    "# which can be thought of as the reconstructed quantities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.27000000e+02 4.70000000e+01 0.00000000e+00 0.00000000e+00\n",
      "  5.27665079e-01]\n",
      " [3.33000000e+02 3.32000000e+02 0.00000000e+00 0.00000000e+00\n",
      "  4.69809949e-01]\n",
      " [2.27000000e+02 4.70000000e+01 1.00000000e+00 0.00000000e+00\n",
      "  1.91275984e-01]\n",
      " [2.27000000e+02 4.80000000e+01 1.00000000e+00 0.00000000e+00\n",
      "  3.14670533e-01]\n",
      " [3.33000000e+02 3.31000000e+02 1.00000000e+00 0.00000000e+00\n",
      "  4.27937686e-01]]\n",
      "(3835, 5)\n"
     ]
    }
   ],
   "source": [
    "input_data = chain.event['input_data']\n",
    "print(input_data[0:5])  # QUESTION: TRUE voxel_index_x, voxel_index_y, voxel_index_z, batch, energy_depostion (or charge?)\n",
    "print(input_data.shape) # QUESTION: 6065 = number of energy deposits in this event?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION: How is the voxel mapping done?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[227.  47.   0.   0.   1.]\n",
      " [333. 332.   0.   0.   1.]\n",
      " [227.  47.   1.   0.   1.]\n",
      " [227.  48.   1.   0.   1.]\n",
      " [333. 331.   1.   0.   1.]]\n",
      "(3835, 5)\n"
     ]
    }
   ],
   "source": [
    "segment_label = chain.event['segment_label']\n",
    "print(segment_label[0:5]) # QUESTION: TRUE voxel_index_x, voxel_index_y, voxel_index_z, batch, true semantic class\n",
    "print(segment_label.shape) # QUESTION: 6065 = number of energy deposits in this event?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.67000000e+02 5.50000000e+02 4.86000000e+02 0.00000000e+00\n",
      "  2.20694482e-01 0.00000000e+00 0.00000000e+00 1.00000000e+00]\n",
      " [5.67000000e+02 5.50000000e+02 4.87000000e+02 0.00000000e+00\n",
      "  1.87287438e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00]\n",
      " [5.67000000e+02 5.50000000e+02 4.88000000e+02 0.00000000e+00\n",
      "  9.27632153e-01 0.00000000e+00 0.00000000e+00 1.00000000e+00]\n",
      " [5.67000000e+02 5.51000000e+02 4.88000000e+02 0.00000000e+00\n",
      "  9.78750348e-01 0.00000000e+00 0.00000000e+00 1.00000000e+00]\n",
      " [5.67000000e+02 5.51000000e+02 4.89000000e+02 0.00000000e+00\n",
      "  1.63090372e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "(3893, 8)\n"
     ]
    }
   ],
   "source": [
    "cluster_label = chain.event['cluster_label']\n",
    "print(cluster_label[0:5]) # TRUE? x, y, z, batch_id, voxel_value, cluster_id, group_id, semantic type\n",
    "print(cluster_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.67000000e+02 5.50000000e+02 4.86000000e+02 0.00000000e+00\n",
      "  2.20694482e-01 0.00000000e+00 0.00000000e+00 1.00000000e+00]\n",
      " [5.67000000e+02 5.50000000e+02 4.87000000e+02 0.00000000e+00\n",
      "  1.87287438e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00]\n",
      " [5.67000000e+02 5.50000000e+02 4.88000000e+02 0.00000000e+00\n",
      "  9.27632153e-01 0.00000000e+00 0.00000000e+00 1.00000000e+00]\n",
      " [5.67000000e+02 5.51000000e+02 4.88000000e+02 0.00000000e+00\n",
      "  9.78750348e-01 0.00000000e+00 0.00000000e+00 1.00000000e+00]\n",
      " [5.67000000e+02 5.51000000e+02 4.89000000e+02 0.00000000e+00\n",
      "  1.63090372e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "(3611, 8)\n"
     ]
    }
   ],
   "source": [
    "cluster_label = chain.output['cluster_label']\n",
    "print(cluster_label[0:5])\n",
    "print(cluster_label.shape)\n",
    "# QUESTION: The difference between chain.event and chain.output is TRUE vs. RECO, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.27000000e+02 4.70000000e+01 0.00000000e+00 0.00000000e+00\n",
      "  5.27665079e-01]\n",
      " [3.33000000e+02 3.32000000e+02 0.00000000e+00 0.00000000e+00\n",
      "  4.69809949e-01]\n",
      " [2.27000000e+02 4.70000000e+01 1.00000000e+00 0.00000000e+00\n",
      "  1.91275984e-01]\n",
      " [2.27000000e+02 4.80000000e+01 1.00000000e+00 0.00000000e+00\n",
      "  3.14670533e-01]\n",
      " [3.33000000e+02 3.31000000e+02 1.00000000e+00 0.00000000e+00\n",
      "  4.27937686e-01]]\n",
      "(3835, 5)\n"
     ]
    }
   ],
   "source": [
    "charge = chain.output['charge'] # QUESTION: voxel_index_x, voxel_index_y, voxel_index_z, batch?, charge deposition?\n",
    "print(charge[0:5])\n",
    "print(charge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[227.  47.   0.   0.   1.]\n",
      " [333. 332.   0.   0.   1.]\n",
      " [227.  47.   1.   0.   1.]\n",
      " [227.  48.   1.   0.   1.]\n",
      " [333. 331.   1.   0.   1.]]\n",
      "(3835, 5)\n"
     ]
    }
   ],
   "source": [
    "segment = chain.output['segment'] # QUESTION: Same as 'charge', but with semantic class?\n",
    "print(segment[0:5])\n",
    "print(segment.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 180,  181,  187,  188,  189,  190,  191,  192,  200,  201,  202,\n",
      "        203,  204,  205,  211,  219,  225,  226,  231,  232,  239,  240,\n",
      "        511,  512,  513,  514,  522,  523,  524,  525,  534,  535,  536,\n",
      "        537,  538,  539,  540,  541,  542,  550,  551,  552,  553,  554,\n",
      "        564,  565,  566,  567,  576,  577,  578,  579,  580,  581,  588,\n",
      "        589,  590,  591,  592,  593,  602,  603,  604,  605,  606,  617,\n",
      "        618,  619,  620,  621,  630,  631,  632,  633,  634,  635,  644,\n",
      "        645,  646,  647,  648,  656,  657,  658,  659,  660,  661,  662,\n",
      "        670,  671,  672,  673,  674,  675,  676,  677,  678,  679,  680,\n",
      "        690,  691,  692,  693,  694,  703,  704,  705,  706,  707,  718,\n",
      "        719,  720,  721,  729,  730,  731,  732,  733,  741,  742,  743,\n",
      "        744,  754,  755,  756,  757,  766,  767,  768,  769,  770,  779,\n",
      "        780,  781,  782,  792,  793,  794,  795,  796,  797,  806,  807,\n",
      "        808,  811,  812,  813,  814,  815,  816,  825,  826,  828,  829,\n",
      "        830,  831,  832,  839,  840,  841,  849,  850,  851,  852,  853,\n",
      "        854,  863,  864,  865,  866,  867,  877,  878,  879,  882,  883,\n",
      "        893,  894,  895,  896,  897,  907,  908,  909,  910,  920,  921,\n",
      "        922,  923,  924,  935,  936,  937,  938,  939,  940,  949,  950,\n",
      "        951,  952,  953,  954,  966,  967,  968,  969,  970,  971,  972,\n",
      "        980,  981,  982,  983,  984,  985,  986,  987,  997,  998,  999,\n",
      "       1000, 1001, 1002, 1003, 1016, 1017, 1018, 1019, 1020, 1023, 1024,\n",
      "       1033, 1034, 1035, 1036, 1040, 1041, 1050, 1052, 1055, 1056, 1060,\n",
      "       1061, 1070, 1071, 1073, 1076, 1079, 1080, 1087, 1088, 1089, 1090,\n",
      "       1091, 1092, 1094, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1120,\n",
      "       1121, 1122, 1132, 1133, 1134, 1135, 1136, 1137, 1149, 1150, 1151,\n",
      "       1159, 1160, 1161, 1163, 1164, 1173, 1174, 1175, 1176, 1177, 1178,\n",
      "       1179, 1180, 1190, 1191, 1192, 1193, 1194, 1202, 1203, 1204, 1205,\n",
      "       1206, 1214, 1215, 1216, 1217, 1227, 1228, 1229, 1230, 1231, 1239,\n",
      "       1240, 1241, 1245, 1246, 1255, 1257, 1258, 1259, 1262, 1263, 1264,\n",
      "       1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1293, 1294,\n",
      "       1295, 1306, 1307, 1308, 1309, 1320, 1321, 1322, 1323, 1332, 1333,\n",
      "       1334, 1344, 1345, 1346, 1356, 1357, 1364, 1365, 1377, 1378, 1387,\n",
      "       1388, 1396, 1397, 1408, 1409, 1420, 1428, 1442, 1443, 1444, 1445,\n",
      "       1456, 1457, 1546, 1547, 1548, 1560, 1561, 1568, 1569, 1570, 1571,\n",
      "       1577, 1578, 1579, 1580, 1591, 1592, 1593, 1594, 1595, 1603, 1604,\n",
      "       1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1619, 1620, 1621,\n",
      "       1622, 1631, 1632, 1633, 1634, 1635, 1636, 1644, 1645, 1646, 1647,\n",
      "       1648, 1655, 1656, 2253, 2263, 2264, 2273, 2274, 2275, 2276, 2277,\n",
      "       2278, 2279, 2280, 2281, 2291, 2292, 2293, 2294, 2295, 2296, 2297,\n",
      "       2298, 2307, 2319, 2320, 2321, 2322, 2323, 2324, 2325, 2326, 2327,\n",
      "       2328, 2338, 2339, 2340, 2341, 2342, 2840, 2849, 2850, 2857, 2858,\n",
      "       2868, 2869, 2870, 2877, 2878, 2879, 2880, 2889, 2890, 2891, 2898,\n",
      "       2899, 2900, 2901, 2902, 2907, 2908, 2909, 2915, 2916, 2917, 2918,\n",
      "       2919, 2920, 2921, 2927, 2928, 2929, 2930, 2931, 2932, 2933, 3308,\n",
      "       3313, 3314, 3315, 3316, 3317, 3318, 3319, 3324, 3325, 3326, 3327,\n",
      "       3328, 3329, 3330, 3335, 3336, 3337, 3338, 3339, 3340, 3341, 3342,\n",
      "       3343, 3344, 3345, 3346, 3347, 3348, 3349, 3350, 3351, 3352, 3353,\n",
      "       3361, 3362, 3363, 3364, 3365, 3366, 3367, 3368, 3369, 3370, 3375,\n",
      "       3376, 3377, 3381, 3382, 3383, 3384, 3387, 3388, 3389, 3390, 3391,\n",
      "       3398, 3399, 3400]),)\n",
      "542\n"
     ]
    }
   ],
   "source": [
    "shower_mask = chain.output['shower_mask'] # QUESTION: Contains voxel_indices with non-zero RECO charge?\n",
    "print(shower_mask)\n",
    "print(len(shower_mask[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.27000000e+02 4.70000000e+01 0.00000000e+00 0.00000000e+00\n",
      "  5.27665079e-01]\n",
      " [3.33000000e+02 3.32000000e+02 0.00000000e+00 0.00000000e+00\n",
      "  4.69809949e-01]\n",
      " [2.27000000e+02 4.70000000e+01 1.00000000e+00 0.00000000e+00\n",
      "  1.91275984e-01]\n",
      " [2.27000000e+02 4.80000000e+01 1.00000000e+00 0.00000000e+00\n",
      "  3.14670533e-01]\n",
      " [3.33000000e+02 3.31000000e+02 1.00000000e+00 0.00000000e+00\n",
      "  4.27937686e-01]]\n",
      "(3835, 5)\n"
     ]
    }
   ],
   "source": [
    "energy = chain.output['energy'] # QUESTION: Same as 'charge', but with semantic class?\n",
    "print(energy[0:5])\n",
    "print(energy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[642.28557326 659.98881519  36.98107797]\n"
     ]
    }
   ],
   "source": [
    "showers = chain.output['showers']\n",
    "#help(showers[0])\n",
    "print(showers[0].start)\n",
    "#print(showers[0].direction)\n",
    "#print(showers[0].voxels)\n",
    "#print(showers[0].energy)\n",
    "#print(showers[0].pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\n"
     ]
    }
   ],
   "source": [
    "index = chain.event['index']\n",
    "print(index) # index of the event within the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ROOT.larcv::Particle object at 0x949cbb0>\n"
     ]
    }
   ],
   "source": [
    "particles = chain.event['particles'][0]\n",
    "print(particles[0]) # QUESTION: entries?\n",
    "#print(particles.shape) # QUESTION: entries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "charge = chain.output['charge'][0:10]\n",
    "#help(charge)\n",
    "#print(charge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "energy = chain.output['energy'][0:10]\n",
    "#help(energy)\n",
    "#print(energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'vertices'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-553f1a042271>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvertices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vertices'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvertex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vertices'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvertex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'vertices'"
     ]
    }
   ],
   "source": [
    "vertices = chain.output['vertices']\n",
    "vertex = chain.output['vertices'][0]\n",
    "#print(vertex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masses = chain.output['masses']\n",
    "#print(masses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = chain.output['matches']\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = chain.event['segment_label']\n",
    "print(segments[0:5]) # shows (true?): x, y, z, batch, semantic\n",
    "print(segments.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cluster_label = chain.output['cluster_label']\n",
    "#print(cluster_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charge = chain.output['charge']\n",
    "#print(charge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shower = chain.output['showers'][0]\n",
    "#help(shower)\n",
    "#print(shower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#help(chain.event['particles'][0][particle].first_step())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The io-config files contain information like 'particles', 'cluster_label', etc.\n",
    "\n",
    "# Get particle:\n",
    "particle = chain.event['particles'][0][0]\n",
    "#help(particle)\n",
    "#help(particle.boundingbox_2d())\n",
    "\n",
    "#cluster = chain.event['cluster_label'][0]\n",
    "#print(\"cluster: \", cluster)\n",
    "# to see what the entries of this array are, look up the information from the .cfg:\n",
    "      #cluster_label:\n",
    "      #  - parse_cluster3d_full\n",
    "      #  - cluster3d_pcluster\n",
    "      #  - particle_corrected\n",
    "# -> Need to have a look to 'parse_cluster3d_full, which lives in mlreco/iotools/parse_cluster3d_full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the chain\n",
    "from pi0.chain import Pi0Chain\n",
    "chain = Pi0Chain(io_cfg, chain_cfg)\n",
    "cluster = chain.event['cluster_label']\n",
    "help(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: lartpc_mlreco3d/mlreco/iotools/parser.py -> parse_cluster3d)\n",
    "# The batch_id is not listed in the parser, but it is always added after x,y,z.\n",
    "# Several clusters can form a single group (the group corresponds to the shower)\n",
    "cluster_label = chain.event['cluster_label']\n",
    "print(cluster_label[0:5]) # TRUE? x, y, z, batch_id, voxel_value, cluster_id, group_id, semantic type\n",
    "print(cluster_label.shape)\n",
    "\n",
    "# To loop over all clusters in the event:\n",
    "#for cluster in range(len(chain.event['cluster_label'])):\n",
    "    #c = chain.event['cluster_label'][cluster]\n",
    "    #print(c)\n",
    "    #print(' x: \\t ', c[0], ' y: \\t ', c[1], ' z: \\t ', c[2], ' c_id: \\t ', c[5], ' \\t g_id: \\t ', c[6])\n",
    "\n",
    "# To obtain the group energies of a single event:\n",
    "#c = chain.event['cluster_label']\n",
    "#group_energies = [np.sum(c[c[:,6] == g][:,4]) for g in np.unique(c[:,6])]\n",
    "#print(' group energies [MeV]: \\t ', group_energies)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
